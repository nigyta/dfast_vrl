#!/usr/bin/env python

import os
import sys
import shutil
import logging
import json
from argparse import ArgumentParser
from dfv.vadr import run as run_vadr
from dfv.vadr2ddbj import convert_vadr_to_gbk
from dfv.genbank2mss import MSS2
from dfv.preprocessing import preprocess_contigs
# from dfv.common import get_logger, LogConfig

dfv_version = "1.2-0.2"

def parse_args():
    parser = ArgumentParser(description=f"DFAST_VRL: Viral genome annotation and data submission tool to DDBJ (ver. {dfv_version})")
    parser.add_argument('--version', version=f'DFAST_VRL ver. {dfv_version}', action='version', help="Show program version", default=False)
    parser.add_argument(
        "-i",
        "--input_fasta",
        type=str,
        # required=True,
        help="Input FASTA file (raw or gzipped) [required]",
        metavar="PATH"
    )
    parser.add_argument(
        "-m",
        "--metadata_file",
        type=str,
        help="Metadata file (Tab-separated table) [Optional]",
        metavar="PATH"
    )
    parser.add_argument(
        "-o",
        "--out_dir",
        type=str,
        help="Output directory (default: OUT)",
        metavar="PATH",
        default="OUT"
    )
    parser.add_argument(
        '--skip_preprocessing', '-sp',
        action='store_true',
        help='Skip preprocessing step and run VADR using the original FASTA.'
    )
    parser.add_argument(
        '--enable_scaffolding', '-es',
        action='store_true',
        help='Fill gaps between contigs with runs of Ns of estimated length'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force overwriting result'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Debug mode'
    )
    if len(sys.argv)==1:
        parser.print_help()
        exit()
    args = parser.parse_args()
    return args

args = parse_args()

if args.input_fasta is None:
    sys.stderr.write("DFAST_VRL: error: Query FASTA is not specified. Aborted.\n")
    exit(1)

work_dir = args.out_dir
if os.path.exists(work_dir) and not args.force:
    if not args.force:
        sys.stderr.write("DFAST_VRL: error: Output directory already exists. Use '--force' to overwrite.\n")
        exit(1)
else:
    os.makedirs(work_dir, exist_ok=True)

def get_logger(name=None, debug=False):
    if debug:
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO

    logger = logging.getLogger(__name__)
    sh = logging.StreamHandler(stream=sys.stdout)
    log_file = os.path.join(work_dir, "dfast_vrl.log")
    fh = logging.FileHandler(log_file, mode="w", encoding="utf-8", delay=True)

    logging.basicConfig(
        format="[%(asctime)s] [%(levelname)s] %(message)s",
        level=log_level,
        handlers=[sh, fh]) 
    logger = logging.getLogger(__name__)
    return logger

logger = get_logger(name=__name__, debug=args.debug)

logger.info(f"DFAST_VRL pipeline started. (version {dfv_version})")
logger.info(f"Results will be generated in {work_dir}")
logger.debug(f"Debug mode enabled.")  # Will be emitted if debug is true

# Prepare sub-working directories
pp_work_dir = os.path.join(work_dir, "preprocessing")
vadr_work_dir = os.path.join(work_dir, "vadr")


# Execution
##1. Preprocessing
preprocessing_result_fasta, pp_report = preprocess_contigs(args.input_fasta, pp_work_dir, 
    output_fasta=None, reference_fasta=None, scaffolding=args.enable_scaffolding, skip_preprocessing=args.skip_preprocessing)

##2. Run VADR
vadr_result_fasta, vadr_result_ftr = run_vadr(preprocessing_result_fasta, vadr_work_dir)


##3. Format conversion
output_gbk = os.path.join(work_dir, "annotation.gbk")
mss_file_prefix = "DDBJ"
metadata_file_copy = os.path.join(work_dir, "metadata.txt")
if args.metadata_file is None:
    # Create dummy metadata file
    with open(metadata_file_copy, "w") as f:
        f.write("projectType\tvrl\n")
else:
    shutil.copy(args.metadata_file, metadata_file_copy)

output_gbk, vadr_report = convert_vadr_to_gbk(vadr_result_fasta, vadr_work_dir, output_gbk)


def update_metadata_file(metadata_file, seq_status, mol_type="RNA"):
    lines = open(metadata_file).readlines()
    ret = ""
    for line in lines:
        key, value = line.strip("\n").split("\t", 1)
        if not (key in ["ff_definition", "seqStatus"]):
            ret += line
    if seq_status == "complete":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, complete genome\n"
    elif seq_status == "nearly complete":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, nearly complete genome\n"
    elif seq_status == "draft":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, draft genome, @@[entry]@@\n"
    else:
        raise AssertionError
    with open(metadata_file, "w") as f:
        f.write(ret)

seq_status = vadr_report["vadr"].get("seq_status", "")
update_metadata_file(metadata_file_copy, seq_status, mol_type="RNA")

mss = MSS2(output_gbk, metadata_file_copy)
mss.convert(work_dir, mss_file_prefix)

dvr_report = {**pp_report, **vadr_report}

out_report_file = os.path.join(work_dir, "dfv_report.json")
logger.info(f"Writing report json to {out_report_file}")
with open(out_report_file, "w") as f:
    json.dump(dvr_report, f, indent=4)
logging.info("DFAST_VRL completed")

