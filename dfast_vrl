#!/usr/bin/env python

import os
import sys
import shutil
import logging
import json
from argparse import ArgumentParser
from dfv.vadr import run as run_vadr
from dfv.vadr2ddbj import convert_vadr_to_gbk
from dfv.genbank2mss import MSS2
from dfv.genbank2fasta import gbk2fasta
from dfv.preprocessing import preprocess_contigs
from dfv.detect_variants import detect_variants
# from dfv.common import get_logger, LogConfig

dfv_version = "1.2-0.6"

def parse_args():
    parser = ArgumentParser(description=f"DFAST_VRL: Viral genome annotation and data submission tool to DDBJ (ver. {dfv_version})")
    parser.add_argument('--version', version=f'DFAST_VRL ver. {dfv_version}', action='version', help="Show program version", default=False)
    parser.add_argument(
        "-i",
        "--input_fasta",
        type=str,
        required=True,
        help="Input FASTA file (raw or gzipped) [Required]",
        metavar="PATH"
    )
    parser.add_argument(
        "-m",
        "--metadata_file",
        type=str,
        help="Metadata file (Tab-separated table) [Optional]",
        metavar="PATH"
    )
    parser.add_argument(
        "-o",
        "--out_dir",
        type=str,
        help="Output directory (default: OUT)",
        metavar="PATH",
        default="OUT"
    )
    parser.add_argument(
        '--isolate',
        type=str,
        help='Isolate name [Optional, but recommendable to specify a unique value to distinguish the sample]',
        metavar="STR"
    )
    parser.add_argument(
        '--modify_query_fasta', '-mq',
        action='store_true',
        help='Modify query FASTA based on the mapping result to the reference. (Extract mapped regions and discard unmapped)'
    )
    parser.add_argument(
        '--disable_scaffolding', '-ds',
        action='store_true',
        help="Disable scaffolding process based on the mapping result to the reference. Ignored when '--modify_query_fasta' is not specified."
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force overwriting result'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Debug mode'
    )
    if len(sys.argv)==1:
        parser.print_help()
        exit()
    args = parser.parse_args()
    return args

args = parse_args()

if args.input_fasta is None:
    sys.stderr.write("DFAST_VRL: error: Query FASTA is not specified. Aborted.\n")
    exit(1)

work_dir = args.out_dir
if os.path.exists(work_dir) and not args.force:
    if not args.force:
        sys.stderr.write("DFAST_VRL: error: Output directory already exists. Use '--force' to overwrite.\n")
        exit(1)
else:
    os.makedirs(work_dir, exist_ok=True)

def get_logger(name=None, debug=False):
    if debug:
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO

    logger = logging.getLogger(__name__)
    sh = logging.StreamHandler(stream=sys.stdout)
    log_file = os.path.join(work_dir, "dfast_vrl.log")
    fh = logging.FileHandler(log_file, mode="w", encoding="utf-8", delay=True)

    logging.basicConfig(
        format="[%(asctime)s] [%(levelname)s] %(message)s",
        level=log_level,
        handlers=[sh, fh]) 
    logger = logging.getLogger(__name__)
    return logger

logger = get_logger(name=__name__, debug=args.debug)

logger.info(f"DFAST_VRL pipeline started. (version {dfv_version})")
logger.info(f"Results will be generated in {work_dir}")
logger.debug(f"Debug mode enabled.")  # Will be emitted if debug is true

# Prepare sub-working directories
pp_work_dir = os.path.join(work_dir, "preprocessing")
vadr_work_dir = os.path.join(work_dir, "vadr")

# Execution
##1. Preprocessing
preprocessing_result_fasta, pp_report, pp_warnings = preprocess_contigs(args.input_fasta, pp_work_dir, 
    output_fasta=None, reference_fasta=None, disable_scaffolding=args.disable_scaffolding, modify_query_fasta=args.modify_query_fasta)

# variant detection
msa_fasta = os.path.join(pp_work_dir, "msa_input.fasta")
detect_var_work_dir = os.path.join(work_dir, "variants")
variants = detect_variants(msa_fasta, detect_var_work_dir)
print("DEBUG", variants)
variants_str = "variants\n" + "-" * 100 + "\n"
for gene_name, var_list in variants.items():
    for var in var_list:
        variants_str += gene_name + "\t" + "\t".join(var) + "\n"
variants_str += "-" * 100 + "\n"
logger.info(variants_str)
variant_json_out = os.path.join(work_dir, "variants.json")
with open(variant_json_out, "w") as f:
    json.dump(variants, f, indent=4)


##2. Run VADR
vadr_result_fasta, vadr_result_ftr = run_vadr(preprocessing_result_fasta, vadr_work_dir)


##3. Format conversion
output_gbk = os.path.join(work_dir, "annotation.gbk")
output_fasta = os.path.join(work_dir, "genome.fna")

metadata_file_copy = os.path.join(work_dir, "metadata.txt")
if args.metadata_file is None:
    # Create dummy metadata file
    with open(metadata_file_copy, "w") as f:
        f.write("projectType\tvrl\n")
else:
    shutil.copy(args.metadata_file, metadata_file_copy)

def get_isolate(metadata_file, args):
    metadata = {}
    for line in open(metadata_file):
        key, value = line.strip("\n").split("\t")
        metadata[key] = value
    isolate_from_metadata_file = metadata.get("isolate")
    if args.isolate:
        isolate = args.isolate
        mss_file_prefix = isolate.replace("/", "_")
        metadata["isolate"] = isolate
        with open(metadata_file, "w") as f:
            for key, value in metadata.items():
                f.write(f"{key}\t{value}\n")
    elif isolate_from_metadata_file:
        isolate = isolate_from_metadata_file
        mss_file_prefix = isolate.replace("/", "_")

    else:
        isolate = "unspecified_isolate"
        mss_file_prefix = "DDBJ"
    return isolate, mss_file_prefix

isolate, mss_file_prefix = get_isolate(metadata_file_copy, args)
output_gbk, vadr_report, vadr_warnings = convert_vadr_to_gbk(vadr_result_fasta, vadr_work_dir, output_gbk, isolate)


def update_metadata_file(metadata_file, seq_status, mol_type="RNA"):
    lines = open(metadata_file).readlines()
    ret = ""
    for line in lines:
        key, value = line.strip("\n").split("\t", 1)
        if not (key in ["ff_definition", "seqStatus"]):
            ret += line
    if seq_status == "complete":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, complete genome\n"
    elif seq_status == "nearly complete":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, nearly complete genome\n"
    elif seq_status == "draft":
        ret += f"seqStatus\t{seq_status}\n"
        ret += f"ff_definition\t@@[organism]@@ @@[isolate]@@ {mol_type}, draft genome, @@[entry]@@\n"
    else:
        raise AssertionError
    with open(metadata_file, "w") as f:
        f.write(ret)

seq_status = vadr_report["vadr"].get("seq_status", "")
update_metadata_file(metadata_file_copy, seq_status, mol_type="RNA")


mss = MSS2(output_gbk, metadata_file_copy)
mss.convert(work_dir, mss_file_prefix)
gbk2fasta(output_gbk, output_fasta)

warnings = [warning.to_tuple() for warning in pp_warnings + vadr_warnings]
warnings = {"warnings": warnings}
dvr_report = {**pp_report, **vadr_report, **warnings}

out_report_file = os.path.join(work_dir, "dfv_report.json")
logger.info(f"Writing report json to {out_report_file}")
with open(out_report_file, "w") as f:
    json.dump(dvr_report, f, indent=4)
logger.info(f"DFAST_VRL warnings:\n{json.dumps(warnings, indent=4)}\n")




logging.info("DFAST_VRL completed")

